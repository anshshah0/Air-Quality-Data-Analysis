import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from joblib import dump

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error

RANDOM_STATE = 42

def build_pipeline(num_features, cat_features):
    numeric_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])
    cat_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=True))
    ])

    pre = ColumnTransformer(transformers=[
        ("num", numeric_pipe, num_features),
        ("cat", cat_pipe, cat_features)
    ])

    model = LinearRegression()
    pipe = Pipeline(steps=[
        ("pre", pre),
        ("model", model)
    ])
    return pipe

def main():
    p = argparse.ArgumentParser()
    p.add_argument("--input", required=True, help="Clean parquet path")
    p.add_argument("--target", default="aqi", help="Target column (default: aqi)")
    p.add_argument("--model-path", default="models/linreg.joblib", help="Where to save model")
    args = p.parse_args()

    df = pd.read_parquet(args.input)
    if args.target not in df.columns:
        raise ValueError(f"Target '{args.target}' not in data.")

    # Select features
    candidate_num = [c for c in ["pm25", "pm10", "no2", "so2", "co", "o3",
                                 "industrial_activity_proxy", "month", "dayofweek"]
                     if c in df.columns]
    candidate_cat = [c for c in ["city"] if c in df.columns]

    # Drop rows with missing target
    data = df.dropna(subset=[args.target]).copy()

    X = data[candidate_num + candidate_cat]
    y = data[args.target].astype(float)

    # basic train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE
    )

    pipe = build_pipeline(candidate_num, candidate_cat)

    # Cross-validated R^2 for robustness
    cv_scores = cross_val_score(pipe, X_train, y_train, scoring="r2", cv=5, n_jobs=None)
    print(f"[train] 5-fold CV R^2: mean={cv_scores.mean():.3f}  std={cv_scores.std():.3f}")

    # Fit and evaluate
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    print(f"[train] Test R^2={r2:.3f}  MAE={mae:.3f}")

    # Persist model + a tiny metadata blob
    model_path = Path(args.model_path)
    model_path.parent.mkdir(parents=True, exist_ok=True)
    dump({
        "pipeline": pipe,
        "features_num": candidate_num,
        "features_cat": candidate_cat,
        "target": args.target,
        "metrics": {"cv_r2_mean": float(cv_scores.mean()),
                    "cv_r2_std": float(cv_scores.std()),
                    "test_r2": float(r2),
                    "test_mae": float(mae)}
    }, model_path)
    print(f"[train] saved model -> {model_path}")

if __name__ == "__main__":
    main()
